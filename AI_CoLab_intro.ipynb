{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 거인의 어깨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/giant_shoulder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# AI CoLab에 오신 것을 환영합니다!\n",
    "AI 코어 플랫폼의 약자입니다.  \n",
    "**\"협업과 지성의 힘으로 AI를 연구하는 플랫폼\"**이라는 의미를 담고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 세 가지 조합 : Python + SQL + 데이터과학"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/python_growth.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 할 수 있는 것\n",
    "1. 데이터 엔지니어링 : 대용량 데이터, 비정형 데이터(뉴스,로그,상담내역...), PC로컬 파일\n",
    "2. 통찰력 : 통계분석, 머신러닝, 딥러닝\n",
    "3. 업무효율화 : 실적산출 자동화\n",
    "4. (가장중요) 소통, 협업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 소통"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/jupyter_case.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 협업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hanhos_kunams.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 20:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 그리기 위한 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xb49f240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEOCAYAAAC6rX9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb3b0898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 값 회전, x축 없애기, 값 표시, 폰트, 컬러\n",
    "ser = pd.Series([20,1], index=['S','M'])\n",
    "ser.plot(kind='bar', figsize=(8,4), rot=0, fontsize=14, yticks=[0,5,10,15,20])\n",
    "plt.title(\"Total Cost\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_16 (Dense)             (None, 24)                2280      \n",
    "_________________________________________________________________\n",
    "dense_17 (Dense)             (None, 10)                250       \n",
    "_________________________________________________________________\n",
    "dense_18 (Dense)             (None, 1)                 11        \n",
    "=================================================================\n",
    "Total params: 2,541\n",
    "Trainable params: 2,541\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Train on 29399 samples, validate on 12601 samples\n",
    "Epoch 1/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.2198 - acc: 0.9129 - val_loss: 0.1770 - val_acc: 0.9322\n",
    "Epoch 2/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1677 - acc: 0.9354 - val_loss: 0.1653 - val_acc: 0.9378\n",
    "Epoch 3/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1535 - acc: 0.9421 - val_loss: 0.1526 - val_acc: 0.9425\n",
    "Epoch 4/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1476 - acc: 0.9438 - val_loss: 0.1523 - val_acc: 0.9443\n",
    "Epoch 5/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1434 - acc: 0.9462 - val_loss: 0.1501 - val_acc: 0.9440\n",
    "Epoch 6/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1393 - acc: 0.9479 - val_loss: 0.1480 - val_acc: 0.9456\n",
    "Epoch 7/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1361 - acc: 0.9494 - val_loss: 0.1521 - val_acc: 0.9418\n",
    "Epoch 8/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1341 - acc: 0.9506 - val_loss: 0.1500 - val_acc: 0.9448\n",
    "Epoch 9/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1332 - acc: 0.9494 - val_loss: 0.1626 - val_acc: 0.9402\n",
    "Epoch 10/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1309 - acc: 0.9507 - val_loss: 0.1458 - val_acc: 0.9458\n",
    "Epoch 11/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1293 - acc: 0.9520 - val_loss: 0.1436 - val_acc: 0.9479\n",
    "Epoch 12/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1276 - acc: 0.9533 - val_loss: 0.1448 - val_acc: 0.9450\n",
    "Epoch 13/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1259 - acc: 0.9529 - val_loss: 0.1468 - val_acc: 0.9451\n",
    "Epoch 14/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1247 - acc: 0.9531 - val_loss: 0.1468 - val_acc: 0.9445\n",
    "Epoch 15/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1234 - acc: 0.9547 - val_loss: 0.1542 - val_acc: 0.9418\n",
    "Epoch 16/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1221 - acc: 0.9556 - val_loss: 0.1694 - val_acc: 0.9387\n",
    "Epoch 17/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1214 - acc: 0.9550 - val_loss: 0.1469 - val_acc: 0.9432\n",
    "Epoch 18/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1201 - acc: 0.9555 - val_loss: 0.1480 - val_acc: 0.9453\n",
    "Epoch 19/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1185 - acc: 0.9561 - val_loss: 0.1434 - val_acc: 0.9467\n",
    "Epoch 20/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1175 - acc: 0.9569 - val_loss: 0.1452 - val_acc: 0.9476\n",
    "Epoch 21/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1167 - acc: 0.9568 - val_loss: 0.1425 - val_acc: 0.9474\n",
    "Epoch 22/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1158 - acc: 0.9564 - val_loss: 0.1484 - val_acc: 0.9448\n",
    "Epoch 23/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1162 - acc: 0.9568 - val_loss: 0.1422 - val_acc: 0.9498\n",
    "Epoch 24/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1147 - acc: 0.9585 - val_loss: 0.1481 - val_acc: 0.9448\n",
    "Epoch 25/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1140 - acc: 0.9582 - val_loss: 0.1396 - val_acc: 0.9479\n",
    "Epoch 26/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1134 - acc: 0.9582 - val_loss: 0.1485 - val_acc: 0.9477\n",
    "Epoch 27/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1123 - acc: 0.9578 - val_loss: 0.1439 - val_acc: 0.9479\n",
    "Epoch 28/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1127 - acc: 0.9583 - val_loss: 0.1412 - val_acc: 0.9487\n",
    "Epoch 29/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1119 - acc: 0.9590 - val_loss: 0.1479 - val_acc: 0.9476\n",
    "Epoch 30/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1108 - acc: 0.9595 - val_loss: 0.1425 - val_acc: 0.9471\n",
    "Epoch 31/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1098 - acc: 0.9593 - val_loss: 0.1424 - val_acc: 0.9501\n",
    "Epoch 32/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1104 - acc: 0.9593 - val_loss: 0.1488 - val_acc: 0.9468\n",
    "Epoch 33/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1087 - acc: 0.9608 - val_loss: 0.1439 - val_acc: 0.9502\n",
    "Epoch 34/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1089 - acc: 0.9604 - val_loss: 0.1477 - val_acc: 0.9452\n",
    "Epoch 35/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1082 - acc: 0.9599 - val_loss: 0.1407 - val_acc: 0.9494\n",
    "Epoch 36/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1078 - acc: 0.9606 - val_loss: 0.1408 - val_acc: 0.9493\n",
    "Epoch 37/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1072 - acc: 0.9617 - val_loss: 0.1427 - val_acc: 0.9499\n",
    "Epoch 38/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1070 - acc: 0.9608 - val_loss: 0.1437 - val_acc: 0.9487\n",
    "Epoch 39/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1062 - acc: 0.9609 - val_loss: 0.1414 - val_acc: 0.9504\n",
    "Epoch 40/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1048 - acc: 0.9612 - val_loss: 0.1475 - val_acc: 0.9498\n",
    "Epoch 41/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1034 - acc: 0.9628 - val_loss: 0.1748 - val_acc: 0.9362\n",
    "Epoch 42/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1050 - acc: 0.9612 - val_loss: 0.1488 - val_acc: 0.9487\n",
    "Epoch 43/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1036 - acc: 0.9619 - val_loss: 0.1470 - val_acc: 0.9490\n",
    "Epoch 44/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1028 - acc: 0.9622 - val_loss: 0.1515 - val_acc: 0.9466\n",
    "Epoch 45/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1029 - acc: 0.9619 - val_loss: 0.1535 - val_acc: 0.9478\n",
    "Epoch 46/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1030 - acc: 0.9622 - val_loss: 0.1511 - val_acc: 0.9486\n",
    "Epoch 47/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.1024 - acc: 0.9613 - val_loss: 0.1496 - val_acc: 0.9470\n",
    "Epoch 48/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1008 - acc: 0.9634 - val_loss: 0.1480 - val_acc: 0.9472\n",
    "Epoch 49/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1006 - acc: 0.9626 - val_loss: 0.1467 - val_acc: 0.9495\n",
    "Epoch 50/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.1009 - acc: 0.9626 - val_loss: 0.1487 - val_acc: 0.9452\n",
    "Epoch 51/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0997 - acc: 0.9645 - val_loss: 0.1481 - val_acc: 0.9475\n",
    "Epoch 52/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0995 - acc: 0.9642 - val_loss: 0.1452 - val_acc: 0.9487\n",
    "Epoch 53/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0998 - acc: 0.9641 - val_loss: 0.1445 - val_acc: 0.9471\n",
    "Epoch 54/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0987 - acc: 0.9634 - val_loss: 0.1463 - val_acc: 0.9464\n",
    "Epoch 55/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0987 - acc: 0.9646 - val_loss: 0.1481 - val_acc: 0.9494\n",
    "Epoch 56/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0983 - acc: 0.9637 - val_loss: 0.1601 - val_acc: 0.9448\n",
    "Epoch 57/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0974 - acc: 0.9648 - val_loss: 0.1494 - val_acc: 0.9491\n",
    "Epoch 58/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0979 - acc: 0.9638 - val_loss: 0.1457 - val_acc: 0.9500\n",
    "Epoch 59/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0971 - acc: 0.9644 - val_loss: 0.1488 - val_acc: 0.9456\n",
    "Epoch 60/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0974 - acc: 0.9645 - val_loss: 0.1489 - val_acc: 0.9487\n",
    "Epoch 61/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0974 - acc: 0.9654 - val_loss: 0.1463 - val_acc: 0.9484\n",
    "Epoch 62/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0965 - acc: 0.9644 - val_loss: 0.1537 - val_acc: 0.9468\n",
    "Epoch 63/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0961 - acc: 0.9651 - val_loss: 0.1613 - val_acc: 0.9456\n",
    "Epoch 64/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0957 - acc: 0.9644 - val_loss: 0.1550 - val_acc: 0.9477\n",
    "Epoch 65/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0957 - acc: 0.9652 - val_loss: 0.1668 - val_acc: 0.9394\n",
    "Epoch 66/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0953 - acc: 0.9646 - val_loss: 0.1566 - val_acc: 0.9460\n",
    "Epoch 67/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0949 - acc: 0.9662 - val_loss: 0.1541 - val_acc: 0.9481\n",
    "Epoch 68/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0955 - acc: 0.9654 - val_loss: 0.1495 - val_acc: 0.9495\n",
    "Epoch 69/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0944 - acc: 0.9658 - val_loss: 0.1560 - val_acc: 0.9475\n",
    "Epoch 70/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0952 - acc: 0.9659 - val_loss: 0.1515 - val_acc: 0.9485\n",
    "Epoch 71/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0936 - acc: 0.9655 - val_loss: 0.1512 - val_acc: 0.9471\n",
    "Epoch 72/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0941 - acc: 0.9659 - val_loss: 0.1505 - val_acc: 0.9474\n",
    "Epoch 73/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0936 - acc: 0.9659 - val_loss: 0.1592 - val_acc: 0.9464\n",
    "Epoch 74/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0938 - acc: 0.9663 - val_loss: 0.1504 - val_acc: 0.9481\n",
    "Epoch 75/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0928 - acc: 0.9662 - val_loss: 0.1522 - val_acc: 0.9478\n",
    "Epoch 76/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0931 - acc: 0.9660 - val_loss: 0.1518 - val_acc: 0.9476\n",
    "Epoch 77/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0932 - acc: 0.9662 - val_loss: 0.1526 - val_acc: 0.9468\n",
    "Epoch 78/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0922 - acc: 0.9671 - val_loss: 0.1532 - val_acc: 0.9471\n",
    "Epoch 79/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0921 - acc: 0.9666 - val_loss: 0.1561 - val_acc: 0.9480\n",
    "Epoch 80/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0906 - acc: 0.9673 - val_loss: 0.1569 - val_acc: 0.9486\n",
    "Epoch 81/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0919 - acc: 0.9670 - val_loss: 0.1544 - val_acc: 0.9472\n",
    "Epoch 82/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0915 - acc: 0.9666 - val_loss: 0.1534 - val_acc: 0.9487\n",
    "Epoch 83/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0922 - acc: 0.9665 - val_loss: 0.1540 - val_acc: 0.9489\n",
    "Epoch 84/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0912 - acc: 0.9670 - val_loss: 0.1551 - val_acc: 0.9498\n",
    "Epoch 85/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0908 - acc: 0.9671 - val_loss: 0.1662 - val_acc: 0.9454\n",
    "Epoch 86/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0903 - acc: 0.9667 - val_loss: 0.1625 - val_acc: 0.9483\n",
    "Epoch 87/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0904 - acc: 0.9674 - val_loss: 0.1609 - val_acc: 0.9461\n",
    "Epoch 88/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0906 - acc: 0.9667 - val_loss: 0.1567 - val_acc: 0.9462\n",
    "Epoch 89/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0904 - acc: 0.9675 - val_loss: 0.1594 - val_acc: 0.9486\n",
    "Epoch 90/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0894 - acc: 0.9669 - val_loss: 0.1595 - val_acc: 0.9471\n",
    "Epoch 91/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0893 - acc: 0.9683 - val_loss: 0.1576 - val_acc: 0.9469\n",
    "Epoch 92/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0890 - acc: 0.9681 - val_loss: 0.1565 - val_acc: 0.9488\n",
    "Epoch 93/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0885 - acc: 0.9677 - val_loss: 0.1595 - val_acc: 0.9491\n",
    "Epoch 94/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0890 - acc: 0.9680 - val_loss: 0.1595 - val_acc: 0.9476\n",
    "Epoch 95/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0885 - acc: 0.9680 - val_loss: 0.1583 - val_acc: 0.9474\n",
    "Epoch 96/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0886 - acc: 0.9680 - val_loss: 0.1707 - val_acc: 0.9415\n",
    "Epoch 97/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0874 - acc: 0.9680 - val_loss: 0.1596 - val_acc: 0.9478\n",
    "Epoch 98/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0883 - acc: 0.9686 - val_loss: 0.1587 - val_acc: 0.9475\n",
    "Epoch 99/100\n",
    "29399/29399 [==============================] - 11s - loss: 0.0876 - acc: 0.9691 - val_loss: 0.1593 - val_acc: 0.9470\n",
    "Epoch 100/100\n",
    "29399/29399 [==============================] - 10s - loss: 0.0887 - acc: 0.9683 - val_loss: 0.1598 - val_acc: 0.9460\n",
    "16832/18000 [===========================>..] - ETA: 0s\n",
    " Test Accuracy: 0.9460"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lyan.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/kim.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 에필로그"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YES24에서 책 하나 가져옵시다~!\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'http://www.yes24.com/24/goods/12550553?scode=032&OzSrank=2'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "book = soup.select(\"h2.gd_name\")[0].string\n",
    "dates = soup.select(\"span.gd_date\")[0].string\n",
    "author = soup.select(\"span.gd_auth > a\")[0].string\n",
    "content = soup.find_all(\"meta\")[5].attrs['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도서 :  평범한 우리, 평범하지 않은 이야기\n",
      "저자 :  이규남\n",
      "요약 :  인생의 종착역에서 나중에 당신과 함께 이야기를 하고 싶습니다.그때는 힘들었고 많이 초조했지만 지금은 다 이겨냈다고. \n",
      "출판연도 :  2014년 03월 24일\n"
     ]
    }
   ],
   "source": [
    "print(\"도서 : \", book)\n",
    "print(\"저자 : \", author)\n",
    "print(\"요약 : \", content)\n",
    "print(\"출판연도 : \", dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### AI CoLab에서 여러분의 호기심과 상상력을 연구해보세요~! \n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
